# 概要



# 参考
- [今日から分かるAVAudioEngineの全て by meteor \| トーク \| iOSDC Japan 2020 \- fortee\.jp](https://fortee.jp/iosdc-japan-2020/proposal/7d292a87-799b-4c0a-a64f-47a53b7c28a6)
    - https://speakerdeck.com/yaminoma/jin-ri-karafen-karu-avaudioenginefalsequan-te
    - [Youtube: iOSDC Japan 2020: 今日から分かるAVAudioEngineの全て / meteor](https://www.youtube.com/watch?v=09VNVNuUiPA)


# Airpodsからの入力を受け取りたい！
- [How to select audio input device \(mic\) in AVAudioEngine on macOS / swift?](https://stackoverflow.com/questions/58893935/how-to-select-audio-input-device-mic-in-avaudioengine-on-macos-swift)
- [Set AVAudioEngine Input and Output Devices](https://stackoverflow.com/questions/28781283/set-avaudioengine-input-and-output-devices)
- [Swift AVAudioEngine: Changing the Audio Input Device for MacOS](https://stackoverflow.com/questions/52818705/swift-avaudioengine-changing-the-audio-input-device-for-macos)
- [macOSで音量を設定する \- Qiita](https://qiita.com/icecocoa6/items/cd33e43e441947d3b4b2)
- [入力デバイスのリストを取得するためのAudioObjectGetPropertyData](https://stackoverrun.com/ja/q/1090202)
    - 一番下のSwiftコードを参照

# デバイス詳細まで取得できるけど…

```swift
        if let inputList = try? self.getInputDevices() {
            // no airpods // [187, 41, 52]
            // with airpods [187, 41, 52, 208] -> 私の環境だと208がairpodsっぽい
            print(inputList)
        }
        var inputDeviceID = 208
        guard let audioUnit = audioEngine.inputNode.audioUnit else { return }
        let errorCode = AudioUnitSetProperty(audioUnit,
                                             kAudioOutputUnitProperty_CurrentDevice,
                                             kAudioUnitScope_Global,
                                             0,
                                             &inputDeviceID,
                                             UInt32(MemoryLayout<AudioDeviceID>.size))
        guard errorCode == 0 else { return }
```

```swift
extension SpeechController {
    /*
     - [入力デバイスのリストを取得するためのAudioObjectGetPropertyData](https://stackoverrun.com/ja/q/1090202)
         - 一番下のSwiftコードを参照
     */
    
    func handle(_ errorCode: OSStatus) throws {
        if errorCode != kAudioHardwareNoError {
            let error = NSError(domain: NSOSStatusErrorDomain, code: Int(errorCode), userInfo: [NSLocalizedDescriptionKey : "CAError: \(errorCode)" ])
            NSApplication.shared.presentError(error)
            throw error
        }
    }
    
    func getInputDevices() throws -> [AudioDeviceID] {
        
        var inputDevices: [AudioDeviceID] = []
        
        // Construct the address of the property which holds all available devices
        var devicesPropertyAddress = AudioObjectPropertyAddress(mSelector: kAudioHardwarePropertyDevices, mScope: kAudioObjectPropertyScopeGlobal, mElement: kAudioObjectPropertyElementMaster)
        var propertySize = UInt32(0)
        
        // Get the size of the property in the kAudioObjectSystemObject so we can make space to store it
        try handle(AudioObjectGetPropertyDataSize(AudioObjectID(kAudioObjectSystemObject), &devicesPropertyAddress, 0, nil, &propertySize))
        
        // Get the number of devices by dividing the property address by the size of AudioDeviceIDs
        let numberOfDevices = Int(propertySize) / MemoryLayout<AudioDeviceID>.size
        
        // Create space to store the values
        var deviceIDs: [AudioDeviceID] = []
        for _ in 0 ..< numberOfDevices {
            deviceIDs.append(AudioDeviceID())
        }
        
        // Get the available devices
        try handle(AudioObjectGetPropertyData(AudioObjectID(kAudioObjectSystemObject), &devicesPropertyAddress, 0, nil, &propertySize, &deviceIDs))
        
        // Iterate
        for id in deviceIDs {
            
            // Get the device name for fun
            var name: CFString = "" as CFString
            var propertySize = UInt32(MemoryLayout<CFString>.size)
            var deviceNamePropertyAddress = AudioObjectPropertyAddress(mSelector: kAudioDevicePropertyDeviceNameCFString, mScope: kAudioObjectPropertyScopeGlobal, mElement: kAudioObjectPropertyElementMaster)
            try handle(AudioObjectGetPropertyData(id, &deviceNamePropertyAddress, 0, nil, &propertySize, &name))
            
            // Check the input scope of the device for any channels. That would mean it's an input device
            
            // Get the stream configuration of the device. It's a list of audio buffers.
            var streamConfigAddress = AudioObjectPropertyAddress(mSelector: kAudioDevicePropertyStreamConfiguration, mScope: kAudioDevicePropertyScopeInput, mElement: 0)
            
            // Get the size so we can make room again
            try handle(AudioObjectGetPropertyDataSize(id, &streamConfigAddress, 0, nil, &propertySize))
            
            // Create a buffer list with the property size we just got and let core audio fill it
            let audioBufferList = AudioBufferList.allocate(maximumBuffers: Int(propertySize))
            try handle(AudioObjectGetPropertyData(id, &streamConfigAddress, 0, nil, &propertySize, audioBufferList.unsafeMutablePointer))
            
            // Get the number of channels in all the audio buffers in the audio buffer list
            var channelCount = 0
            for i in 0 ..< Int(audioBufferList.unsafeMutablePointer.pointee.mNumberBuffers) {
                channelCount = channelCount + Int(audioBufferList[i].mNumberChannels)
            }
            
            free(audioBufferList.unsafeMutablePointer)
            
            // If there are channels, it's an input device
            if channelCount > 0 {
                Swift.print("Found input device '\(name)' with \(channelCount) channels")
                inputDevices.append(id)
            }
        }
        
        return inputDevices
    }
    
}

```

